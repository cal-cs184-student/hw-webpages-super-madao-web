<html>
  <head>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&display=swap"
      rel="stylesheet"
    />
    <style>
      h1 {
        text-align: center;
        color: #00b4ff;
      }

      h2 {
        color: #00b4ff;
      }

      h3 {
        color: #00b4ff;
      }

      a {
        color: #00b4ff;
      }

      .container {
        margin: 0 auto;
        padding: 60px 20%;
      }

      figure {
        text-align: center;
      }

      img {
        display: inline-block;
      }

      body {
        font-family: "Open Sans", serif;
        background-color: #15171e;
        color: white;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <h1>CS184/284A Spring 2025 Homework 3 Write-Up</h1>
      <div style="text-align: center">Annika Liu, Candice Yang</div>

      <br />
      <a href="https://cal-cs184-student.github.io/hw-webpages-super-madao-web/"
        >Link</a
      >
      to webpage. <br />
      <a href="https://github.com/cal-cs184-student/sp25-hw2-madao-kleta.git"
        >Link</a
      >
      to GitHub repository.

      <figure>
        <img
          src="cornell.png"
          alt="Cornell Boxes with Bunnies"
          style="width: 100%"
        />
        <figcaption>I am not a rabbit.üêá</figcaption>
      </figure>

      <!--
		We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

      <h2>Overview</h2>
      Give a high-level overview of what you implemented in this homework. Think
      about what you've built as a whole. Share your thoughts on what
      interesting things you've learned from completing the homework.

      <h2>Part 1: Ray Generation and Scene Intersection</h2>
      <h3>
        1. Walk through the ray generation and primitive intersection parts of
        the rendering pipeline.
      </h3>

      <!-- Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. -->
      <div>
        <p>
          The ray generation process begins in the camera class, specifically in
          the <code>Camera::generate_ray()</code>
          function. This function takes normalized image coordinates (x, y) as
          input, where (0,0) represents the bottom-left corner and (1,1) the
          top-right corner of the image.
        </p>

        <p>
          These normalized coordinates are first transformed into camera space.
          In camera space, the camera is located at (0,0,0) and faces along the
          negative Z axis. A virtual camera sensor is set at
          <code>z = -1</code>, with dimensions defined by the horizontal and
          vertical field of view angles (<code>hFov</code> and
          <code>vFov</code>).
        </p>

        <p>
          The normalized coordinates are then mapped to points on the sensor,
          and a ray is created starting at the camera origin (0,0,0) and passing
          through the computed point. This defines the ray‚Äôs direction in camera
          space. Finally, the ray is transformed from camera space to world
          space using the camera-to-world transformation matrix, which updates
          both its origin and its direction.
        </p>

        <p>
          The <code>PathTracer::raytrace_pixel()</code> function leverages this
          process to generate rays for each pixel:
        </p>

        <ol>
          <li>
            <strong>Ray Sampling:</strong> For each pixel with coordinates (x,
            y), multiple sample rays (denoted by <code>ns_aa</code>
            samples) are generated to implement anti-aliasing.
          </li>
          <li>
            <strong>Perturbation:</strong> Each sample perturbs the pixel
            coordinates slightly using a random sampler, ensuring that rays pass
            through different parts of the pixel.
          </li>
          <li>
            <strong>Ray Creation and Averaging:</strong> The
            <code>Camera::generate_ray()</code> function is called for each
            sample, and the radiance along each ray is estimated. These results
            are then averaged to determine the final color of the pixel.
          </li>
        </ol>

        <p>
          Once the rays are generated, they are tested for intersection with
          scene primitives (such as triangles and spheres). The intersection
          tests are implemented in the triangle and sphere classes via the
          <code>Triangle::intersect()</code> and
          <code>Sphere::intersect()</code> functions.
        </p>

        <p>
          In both cases, the functions update the ray‚Äôs
          <code>max_t</code> property to the nearest intersection found, helping
          to optimize subsequent intersection tests.
        </p>
      </div>

      <h3>
        2. Explain the triangle intersection algorithm you implemented in your
        own words.
      </h3>
      <p>
        I used the lecture slide of Moller Trumbore Algorithm to implement the
        triangle intersection algorithm, which increases the efficiency of this
        algorithm. <br />

        1. The algorithm first computes two edges of the triangle: edge1 and
        edge2. <br />
        2. It then calculates a vector pvec by taking the cross product of the
        ray direction and edge2. <br />
        3. The determinant <code>det = dot(edge1, pvec)</code> is calculated,
        which is proportional to the volume of the parallelpiped formed by the
        ray direction and the two edges. If the determinant is close to zero,
        the ray is parallel to the triangle plane, so there's no intersection.
        <br />
        4. For valid intersections, barycentric coordinates (u, v) are
        calculated: u = dot(tvec, pvec) * inv_det where tvec = r.o - p v =
        dot(r.d, qvec) * inv_det where qvec = cross(tvec, edge1) <br />
        5. The barycentric coordinates determine if the intersection point is
        inside third barycentric coordinate \(w = 1 - u - v\) implicitly. <br />
        6. The intersection distance t along the ray is calculated as t =
        dot(edge2, qvec) * inv_det. <br />
        7. Finally, for valid intersections, the algorithm updates the ray's
        max_t value and, in the full intersection method, also computes the
        interpolated normal at the intersection point using the barycentric
        coordinates. <br />
      </p>

      <h3>3. Images with normal shading for a few small¬†.dae¬†files.</h3>

      <div style="display: flex; flex-direction: column; align-items: center">
        <table
          style="width: 60%; text-align: center; border-collapse: collapse"
        >
          <tr>
            <td style="text-align: center">
              <img src="Part1_CBgems.png" width="300px" alt="CBgems" />
              <figcaption>CBgems</figcaption>
            </td>
            <td style="text-align: center">
              <img
                src="Part1_CBspheres_microfacet_al_ag.png"
                width="300px"
                alt="CBspheres Microfacet AL AG"
              />
              <figcaption>CBspheres Microfacet AL AG</figcaption>
            </td>
          </tr>
          <tr>
            <td style="text-align: center">
              <img src="Part1_CBspheres.png" width="300px" alt="CBspheres" />
              <figcaption>CBspheres</figcaption>
            </td>
            <td style="text-align: center">
              <img src="Part1_teapot.png" width="300px" alt="Teapot" />
              <figcaption>Teapot</figcaption>
            </td>
          </tr>
        </table>
      </div>

      <h2>Part 2: Bounding Volume Hierarchy</h2>
      <h3>
        1. Walk through your BVH construction algorithm. Explain the heuristic
        you chose for picking the splitting point.
      </h3>

      The algorithm recursively builds the BVH by first computing an overall
      bounding box that encloses all primitives. If the number of primitives is
      below the maximum leaf size, it creates a leaf node. Otherwise, it
      computes a centroid bounding box of all primitives, selects the longest
      axis (i.e., the axis with the maximum extent), and then chooses the split
      point as the midpoint along that axis. <br />
      The midpoint heuristic aims to balance the tree by roughly dividing the
      primitives into two groups based on the position of their centroids. If
      the partitioning is degenerate (all primitives fall on one side), the
      algorithm defaults to splitting the set in half.

      <h3>
        Show images with normal shading for a few large¬†.dae¬†files that you can
        only render with BVH acceleration.
      </h3>

      <div style="display: flex; flex-direction: column; align-items: center">
        <table
          style="width: 80%; text-align: center; border-collapse: collapse"
        >
          <tr>
            <td style="text-align: center">
              <img src="Part2_beast.png" width="300px" alt="Beast" />
              <figcaption>Beast</figcaption>
            </td>
            <td style="text-align: center">
              <img src="Part2_blob.png" width="300px" alt="Blob" />
              <figcaption>Blob</figcaption>
            </td>
          </tr>
          <tr>
            <td style="text-align: center">
              <img src="Part2_CBlucy.png" width="300px" alt="CBlucy" />
              <figcaption>CBlucy</figcaption>
            </td>
            <td style="text-align: center" colspan="2">
              <img src="Part2_wall-e.png" width="300px" alt="Wall-e" />
              <figcaption>Wall-e</figcaption>
            </td>
          </tr>
        </table>
      </div>

      <h3>
        Compare rendering times on a few scenes with moderately complex
        geometries with and without BVH acceleration.
      </h3>

      For wall-e, with BVH, Building BVH from 240326 primitives takes 0.1627
      sec, and rendering takes 0.0678 sec. With the same processor but without
      BVH, rendering took 45 sec. All other renders above show a similar pattern
      that BVH significantly speed up rendering.

      <h2>Part 3: Direct Illumination</h2>
      <h3>
        1. Walk through both implementations of the direct lighting function.
      </h3>

      <p></p>
      <h4>Hemisphere Sampling</h4>
      <p>
        For the <code>estimate_direct_lighting_hemisphere</code> function, I
        implemented a uniform hemisphere sampling approach with these key steps:
      </p>
      <ol>
        <li>
          Created a coordinate system at the hit point with the normal aligned
          with the Z-direction
        </li>
        <li>
          Transformed the outgoing ray direction to this local coordinate system
        </li>
        <li>
          Generated multiple sample rays uniformly distributed over the
          hemisphere
        </li>
        <li>
          For each sample:
          <ul>
            <li>Created a ray from the hit point in the sampled direction</li>
            <li>Checked if the ray intersected with any object in the scene</li>
            <li>
              If the intersected object was a light source, calculated its
              contribution
            </li>
            <li>
              Applied the BSDF to determine how much light is reflected toward
              the camera
            </li>
            <li>
              Accumulated the contribution weighted by the cosine factor and
              divided by the PDF
            </li>
          </ul>
        </li>
        <li>Averaged the accumulated light contributions over all samples</li>
      </ol>
      <p>
        The PDF for hemisphere sampling is constant at 1/(2œÄ) since we're
        sampling uniformly over the hemisphere.
      </p>
      <h4>Importance Sampling</h4>
      <p>
        For the <code>estimate_direct_lighting_importance</code> function, I
        implemented an importance sampling approach that specifically targets
        light sources:
      </p>
      <ol>
        <li>Set up the same coordinate system as in hemisphere sampling</li>
        <li>
          Instead of sampling random directions, iterated through all lights in
          the scene
        </li>
        <li>
          For each light:
          <ul>
            <li>Generated samples directly from the light source</li>
            <li>
              Used a single sample for delta lights (point lights) and multiple
              samples for area lights
            </li>
            <li>
              For each sample:
              <ul>
                <li>
                  Obtained a direction, distance, and PDF from the light's
                  sampling function
                </li>
                <li>
                  Skipped directions below the surface or with negligible PDF
                </li>
                <li>Created a shadow ray to check visibility</li>
                <li>
                  If the light was visible, applied the BSDF and accumulated the
                  contribution
                </li>
              </ul>
            </li>
            <li>Averaged the contributions from each light's samples</li>
          </ul>
        </li>
        <li>Summed up the contributions from all lights</li>
      </ol>

      <p>
        The importance sampling approach generally produces less noisy images
        with the same number of samples, particularly for scenes where light
        sources occupy a small portion of the hemisphere.
      </p>

      <h3>
        2. Some images rendered with both implementations of the direct lighting
        function.
      </h3>

      <div style="display: flex; flex-direction: column; align-items: center">
        <table
          style="width: 80%; text-align: center; border-collapse: collapse"
        >
          <tr>
            <td style="text-align: center">
              <img
                src="Part3_H_CBbunny_H_16_8.png"
                width="300px"
                alt="H_CBunny Rendering"
              />
              <figcaption>Hemisphere Bunny</figcaption>
            </td>
            <td style="text-align: center">
              <img
                src="Part3_importance_bunny_64_32.png"
                width="300px"
                alt="Importance Sampling Bunny"
              />
              <figcaption>Importance Sampling Bunny</figcaption>
            </td>
          </tr>
        </table>
      </div>

      <h3>
        3. Noise level when increasing number of light rays with light sampling.
      </h3>
      Here is one particular scene with at least one area light and compare the
      noise levels in soft shadows when rendering with 1, 4, 16, and 64 light
      rays and with 1 sample per pixel using light sampling. The noise level
      decreases as the number of light rays increases.

      <div style="display: flex; flex-direction: column; align-items: center">
        <table
          style="width: 90%; text-align: center; border-collapse: collapse"
        >
          <tr>
            <td>
              <img src="Part3_bunny_1_1.png" width="200px" alt="1 Light Ray" />
              <figcaption>1 Light Ray</figcaption>
            </td>
            <td>
              <img src="Part3_bunny_1_4.png" width="200px" alt="4 Light Rays" />
              <figcaption>4 Light Rays</figcaption>
            </td>
            <td>
              <img
                src="Part3_bunny_1_16.png"
                width="200px"
                alt="16 Light Rays"
              />
              <figcaption>16 Light Rays</figcaption>
            </td>
          </tr>
          <tr>
            <td>
              <img
                src="Part3_bunny_1_64.png"
                width="200px"
                alt="64 Light Rays"
              />
              <figcaption>64 Light Rays</figcaption>
            </td>
            <td>
              <img
                src="Part3_bunny_1_128.png"
                width="200px"
                alt="128 Light Rays"
              />
              <figcaption>128 Light Rays</figcaption>
            </td>
          </tr>
        </table>
      </div>

      <h2>Part 4: Global Illumination</h2>

      <h3>
        Walk through your implementation of the indirect lighting function.
      </h3>
      <p>
        In our implementation of <code>at_least_one_bounce_radiance</code>, we
        combine direct and indirect lighting through recursion.
      </p>
      <ul>
        <li>
          <strong>Local Coordinate Setup:</strong> An orthonormal basis is
          created at the intersection point using the surface normal, enabling
          transformations between world and local space.
        </li>
        <li>
          <strong>Direct Lighting:</strong> We compute immediate radiance using
          <code>one_bounce_radiance</code>, which accounts for light arriving
          directly at the surface.
        </li>
        <li>
          <strong>Indirect Lighting:</strong> The BSDF is sampled to determine
          an incoming light direction, and a Russian roulette strategy (with
          probability 0.3) decides if further bounces should be computed.
        </li>
        <li>
          <strong>Recursion:</strong> When an additional bounce is allowed and
          an intersection is detected, the function calls itself recursively.
          The returned radiance is weighted by the BSDF, a cosine factor, and
          the pdf, then scaled by the Russian roulette probability.
        </li>
      </ul>

      <h3>
        Some images rendered with global (direct and indirect) illumination with
        1024 samples per pixel.
      </h3>
      <div style="display: flex; flex-direction: column; align-items: center">
        <table
          style="width: 70%; text-align: center; border-collapse: collapse"
        >
          <tr>
            <td style="text-align: center">
              <img
                src="Part4_2_1024s_spheres.png"
                width="300px"
                alt="1024 Samples - Spheres"
              />
              <figcaption>1024 Samples - Spheres</figcaption>
            </td>
            <td style="text-align: center">
              <img
                src="Part4_2_bunny.png"
                width="300px"
                alt="1024 Samples - Bunny"
              />
              <figcaption>1024 Samples - Bunny</figcaption>
            </td>
          </tr>
        </table>
      </div>

      <h3>
        One scene and compare rendered views first with only direct
        illumination, then only indirect illumination. Use 1024 samples per
        pixel.
      </h3>
      <div style="display: flex; flex-direction: column; align-items: center">
        <table
          style="width: 70%; text-align: center; border-collapse: collapse"
        >
          <tr>
            <td style="text-align: center">
              <img
                src="Part4_3_direct_bunny.png"
                width="300px"
                alt="Direct Illumination - Bunny"
              />
              <figcaption>Direct Illumination</figcaption>
            </td>
            <td style="text-align: center">
              <img
                src="Part4_3_indirect_bunny.png"
                width="300px"
                alt="Indirect Illumination - Bunny"
              />
              <figcaption>Indirect Illumination</figcaption>
            </td>
          </tr>
        </table>
      </div>

      <h3>max_ray_depth influence on the quality of the rendered image.</h3>
      Render the mth bounce of light with¬†max_ray_depth¬†set to 0, 1, 2, 3, 4,
      and 5 (the¬†m¬†flag), and¬†isAccumBounces=false, using 1024 samples per
      pixel.
      <br />
      In 2nd and 3rd bounces, the rendered image reaches higher quality and also
      with less noise compared to rasterization. After that, the image quality
      seems to converge.

      <div style="display: flex; flex-direction: column; align-items: center">
        <table
          style="width: 70%; text-align: center; border-collapse: collapse"
        >
          <tr>
            <td style="text-align: center">
              <img
                src="Part4_3_m0_o0_bunny.png"
                width="200px"
                alt="Max Ray Depth 0 (o0)"
              />
              <figcaption>Max Ray Depth 0 (isAccumBounces = false)</figcaption>
            </td>
            <td style="text-align: center">
              <img
                src="Part4_3_m1_o0_bunny.png"
                width="200px"
                alt="Max Ray Depth 1 (o1)"
              />
              <figcaption>Max Ray Depth 1 (isAccumBounces = false)</figcaption>
            </td>
            <td style="text-align: center">
              <img
                src="Part4_3_m2_o0_bunny.png"
                width="200px"
                alt="Max Ray Depth 2 (o1)"
              />
              <figcaption>Max Ray Depth 2 (isAccumBounces = false)</figcaption>
            </td>
          </tr>
          <tr>
            <td style="text-align: center">
              <img
                src="Part4_3_m3_o0_bunny.png"
                width="200px"
                alt="Max Ray Depth 3 (o1)"
              />
              <figcaption>Max Ray Depth 3 (isAccumBounces = false)</figcaption>
            </td>
            <td style="text-align: center">
              <img
                src="Part4_3_m4_o0_bunny.png"
                width="200px"
                alt="Max Ray Depth 4 (o1)"
              />
              <figcaption>Max Ray Depth 4 (isAccumBounces = false)</figcaption>
            </td>
            <td style="text-align: center">
              <img
                src="Part4_3_m5_o0_bunny.png"
                width="200px"
                alt="Max Ray Depth 5 (o1)"
              />
              <figcaption>Max Ray Depth 5 (isAccumBounces = false)</figcaption>
            </td>
          </tr>
        </table>
      </div>

      <br />
      <br />
      For accumulated bounces:
      <br />
      <br />

      <div style="display: flex; flex-direction: column; align-items: center">
        <table
          style="width: 70%; text-align: center; border-collapse: collapse"
        >
          <tr>
            <td style="text-align: center">
              <img
                src="Part4_3_m0_o1_bunny.png"
                width="200px"
                alt="Max Ray Depth 0 (o0)"
              />
              <figcaption>Max Ray Depth 0 (isAccumBounces = true)</figcaption>
            </td>
            <td style="text-align: center">
              <img
                src="Part4_3_m1_o1_bunny.png"
                width="200px"
                alt="Max Ray Depth 1 (o1)"
              />
              <figcaption>Max Ray Depth 1 (isAccumBounces = true)</figcaption>
            </td>
            <td style="text-align: center">
              <img
                src="Part4_3_m2_o1_bunny.png"
                width="200px"
                alt="Max Ray Depth 2 (o1)"
              />
              <figcaption>Max Ray Depth 2 (isAccumBounces = true)</figcaption>
            </td>
          </tr>
          <tr>
            <td style="text-align: center">
              <img
                src="Part4_3_m3_o1_bunny.png"
                width="200px"
                alt="Max Ray Depth 3 (o1)"
              />
              <figcaption>Max Ray Depth 3 (isAccumBounces = true)</figcaption>
            </td>
            <td style="text-align: center">
              <img
                src="Part4_3_m4_o1_bunny.png"
                width="200px"
                alt="Max Ray Depth 4 (o1)"
              />
              <figcaption>Max Ray Depth 4 (isAccumBounces = true)</figcaption>
            </td>
            <td style="text-align: center">
              <img
                src="Part4_3_m5_o1_bunny.png"
                width="200px"
                alt="Max Ray Depth 5 (o1)"
              />
              <figcaption>Max Ray Depth 5 (isAccumBounces = true)</figcaption>
            </td>
          </tr>
        </table>
      </div>

      <br />
      <br />
      For max_ray_depth=100 with Russian roulette (1024 samples per pixel):

      <div style="display: flex; flex-direction: column; align-items: center">
        <img
          src="Part4_3_m100_bunny.png"
          width="300px"
          alt="Max Ray Depth 100 with Russian roulette"
        />
        <figcaption>
          Max Ray Depth 100 with Russian roulette (1024 samples per pixel)
        </figcaption>
      </div>

      <h3>Sample-per-pixel rates influence on render quality.</h3>
      Pick one scene and compare rendered views with various sample-per-pixel
      rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.

      <div style="display: flex; flex-direction: column; align-items: center">
        <table
          style="width: 70%; text-align: center; border-collapse: collapse"
        >
          <tr>
            <td style="text-align: center">
              <img
                src="Part4_5_bunny_1_1.png"
                width="200px"
                alt="1 samples per pixel"
              />
              <figcaption>1 sample per pixel</figcaption>
            </td>
            <td style="text-align: center">
              <img
                src="Part4_5_bunny_1_4.png"
                width="200px"
                alt="4 samples per pixel"
              />
              <figcaption>4 samples per pixel</figcaption>
            </td>
            <td style="text-align: center">
              <img
                src="Part4_5_bunny_1_16.png"
                width="200px"
                alt="16 samples per pixel"
              />
              <figcaption>16 samples per pixel</figcaption>
            </td>
          </tr>
          <tr>
            <td style="text-align: center">
              <img
                src="Part4_5_bunny_1_64.png"
                width="200px"
                alt="64 samples per pixel"
              />
              <figcaption>64 samples per pixel</figcaption>
            </td>
            <td style="text-align: center">
              <img
                src="Part4_5_bunny_1_128.png"
                width="200px"
                alt="128 samples per pixel"
              />
              <figcaption>128 samples per pixel</figcaption>
            </td>
            <td style="text-align: center">
              <img
                src="Part4_5_bunny_1_1024.png"
                width="200px"
                alt="1024 samples per pixel"
              />
              <figcaption>1024 samples per pixel</figcaption>
            </td>
          </tr>
        </table>
      </div>

      <h2>Part 5: Adaptive Sampling</h2>

      <h3>
        Explain adaptive sampling. Walk through your implementation of the
        adaptive sampling.
      </h3>
      <p>
        Adaptive sampling is a technique that dynamically adjusts the number of
        samples taken per pixel based on a statistical measure of convergence.
        The goal is to use more samples only when needed (i.e., in areas of high
        variance) and to stop early when the pixel's estimated radiance is
        already reliable.
      </p>
      <p>
        In our <code>raytrace_pixel</code> function, we begin by defining the
        total number of samples to be taken and initializing counters for the
        number of samples and accumulated statistics (<code>s1</code> and
        <code>s2</code>).
      </p>
      <p>
        The function then enters a loop where it processes samples in batches.
        For each sample, a camera ray is generated and its radiance is computed
        using global illumination. The sample's illuminance is then used to
        update our running sums.
      </p>
      <p>
        After each batch, if more than one sample has been taken, we calculate
        the mean and variance of the collected samples. We then derive the 95%
        confidence interval and check if its width is within an acceptable range
        compared to the mean. If the condition is met, sampling for that pixel
        stops early.
      </p>
      <p>
        Finally, the total number of samples used is recorded for visualization.
        This approach allows the renderer to efficiently allocate computation
        where it's most needed.
      </p>

      <h3>Sampling rate images</h3>
      Pick two scenes and render them with at least 2048 samples per pixel. Show
      a good sampling rate image with clearly visible differences in sampling
      rate over various regions and pixels. Include both your sample rate image,
      which shows your how your adaptive sampling changes depending on which
      part of the image you are rendering, and your noise-free rendered result.
      Use 1 sample per light and at least 5 for max ray depth.

      <div style="display: flex; flex-direction: column; align-items: center">
        <table
          style="width: 70%; text-align: center; border-collapse: collapse"
        >
          <tr>
            <td style="text-align: center">
              <img src="Part5_bunny_rate.png" width="300px" alt="Bunny rate" />
              <figcaption>Bunny sample rate</figcaption>
            </td>
            <td style="text-align: center">
              <img
                src="Part5_spheres_rate.png"
                width="300px"
                alt="Spheres sample rate"
              />
              <figcaption>Spheres sample rate</figcaption>
            </td>
          </tr>
        </table>
      </div>
    </div>
  </body>
</html>
