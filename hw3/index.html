<html>
  <head>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&display=swap"
      rel="stylesheet"
    />
    <style>
      h1 {
        text-align: center;
        color: #00b4ff;
      }

      h2 {
        color: #00b4ff;
      }

      h3 {
        color: #00b4ff;
      }

      a {
        color: #00b4ff;
      }

      .container {
        margin: 0 auto;
        padding: 60px 20%;
      }

      figure {
        text-align: center;
      }

      img {
        display: inline-block;
      }

      body {
        font-family: "Open Sans", serif;
        background-color: #15171e;
        color: white;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <h1>CS184/284A Spring 2025 Homework 3 Write-Up</h1>
      <div style="text-align: center">Annika Liu, Candice Yang</div>

      <br />
      <a href="https://cal-cs184-student.github.io/hw-webpages-super-madao-web/"
        >Link</a
      >
      to webpage. <br />
      <a href="https://github.com/cal-cs184-student/sp25-hw2-madao-kleta.git"
        >Link</a
      >
      to GitHub repository.

      <figure>
        <img
          src="cornell.png"
          alt="Cornell Boxes with Bunnies"
          style="width: 100%"
        />
        <figcaption>I am not a rabbit.üêá</figcaption>
      </figure>

      <!--
		We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

      <h2>Overview</h2>
      Give a high-level overview of what you implemented in this homework. Think
      about what you've built as a whole. Share your thoughts on what
      interesting things you've learned from completing the homework.

      <h2>Part 1: Ray Generation and Scene Intersection</h2>
      <h3>
        1. Walk through the ray generation and primitive intersection parts of
        the rendering pipeline.
      </h3>

      <!-- Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. -->
      <div>
        <p>
          The ray generation process begins in the camera class, specifically in
          the <code>Camera::generate_ray()</code>
          function. This function takes normalized image coordinates (x, y) as
          input, where (0,0) represents the bottom-left corner and (1,1) the
          top-right corner of the image.
        </p>

        <p>
          These normalized coordinates are first transformed into camera space.
          In camera space, the camera is located at (0,0,0) and faces along the
          negative Z axis. A virtual camera sensor is set at
          <code>z = -1</code>, with dimensions defined by the horizontal and
          vertical field of view angles (<code>hFov</code> and
          <code>vFov</code>).
        </p>

        <p>
          The normalized coordinates are then mapped to points on the sensor,
          and a ray is created starting at the camera origin (0,0,0) and passing
          through the computed point. This defines the ray‚Äôs direction in camera
          space. Finally, the ray is transformed from camera space to world
          space using the camera-to-world transformation matrix, which updates
          both its origin and its direction.
        </p>

        <p>
          The <code>PathTracer::raytrace_pixel()</code> function leverages this
          process to generate rays for each pixel:
        </p>

        <ol>
          <li>
            <strong>Ray Sampling:</strong> For each pixel with coordinates (x,
            y), multiple sample rays (denoted by <code>ns_aa</code>
            samples) are generated to implement anti-aliasing.
          </li>
          <li>
            <strong>Perturbation:</strong> Each sample perturbs the pixel
            coordinates slightly using a random sampler, ensuring that rays pass
            through different parts of the pixel.
          </li>
          <li>
            <strong>Ray Creation and Averaging:</strong> The
            <code>Camera::generate_ray()</code> function is called for each
            sample, and the radiance along each ray is estimated. These results
            are then averaged to determine the final color of the pixel.
          </li>
        </ol>

        <p>
          Once the rays are generated, they are tested for intersection with
          scene primitives (such as triangles and spheres). The intersection
          tests are implemented in the triangle and sphere classes via the
          <code>Triangle::intersect()</code> and
          <code>Sphere::intersect()</code> functions.
        </p>

        <p>
          In both cases, the functions update the ray‚Äôs
          <code>max_t</code> property to the nearest intersection found, helping
          to optimize subsequent intersection tests.
        </p>
      </div>

      <h3>
        2. Explain the triangle intersection algorithm you implemented in your
        own words.
      </h3>
      <p>
        I used the lecture slide of Moller Trumbore Algorithm to implement the
        triangle intersection algorithm, which increases the efficiency of this
        algorithm. <br />

        1. The algorithm first computes two edges of the triangle: edge1 and
        edge2. <br />
        2. It then calculates a vector pvec by taking the cross product of the
        ray direction and edge2. <br />
        3. The determinant <code>det = dot(edge1, pvec)</code> is calculated,
        which is proportional to the volume of the parallelpiped formed by the
        ray direction and the two edges. If the determinant is close to zero,
        the ray is parallel to the triangle plane, so there's no intersection.
        <br />
        4. For valid intersections, barycentric coordinates (u, v) are
        calculated: u = dot(tvec, pvec) * inv_det where tvec = r.o - p v =
        dot(r.d, qvec) * inv_det where qvec = cross(tvec, edge1) <br />
        5. The barycentric coordinates determine if the intersection point is
        inside third barycentric coordinate \(w = 1 - u - v\) implicitly. <br />
        6. The intersection distance t along the ray is calculated as t =
        dot(edge2, qvec) * inv_det. <br />
        7. Finally, for valid intersections, the algorithm updates the ray's
        max_t value and, in the full intersection method, also computes the
        interpolated normal at the intersection point using the barycentric
        coordinates. <br />
      </p>

      <h3>3. Images with normal shading for a few small¬†.dae¬†files.</h3>

      <div style="display: flex; flex-direction: column; align-items: center">
        <table
          style="width: 60%; text-align: center; border-collapse: collapse"
        >
          <tr>
            <td style="text-align: center">
              <img src="Part1_CBgems.png" width="300px" alt="CBgems" />
              <figcaption>CBgems</figcaption>
            </td>
            <td style="text-align: center">
              <img
                src="Part1_CBspheres_microfacet_al_ag.png"
                width="300px"
                alt="CBspheres Microfacet AL AG"
              />
              <figcaption>CBspheres Microfacet AL AG</figcaption>
            </td>
          </tr>
          <tr>
            <td style="text-align: center">
              <img src="Part1_CBspheres.png" width="300px" alt="CBspheres" />
              <figcaption>CBspheres</figcaption>
            </td>
            <td style="text-align: center">
              <img src="Part1_teapot.png" width="300px" alt="Teapot" />
              <figcaption>Teapot</figcaption>
            </td>
          </tr>
        </table>
      </div>

      <h2>Part 2: Bounding Volume Hierarchy</h2>
      <h3>
        1. Walk through your BVH construction algorithm. Explain the heuristic
        you chose for picking the splitting point.
      </h3>

      The algorithm recursively builds the BVH by first computing an overall
      bounding box that encloses all primitives. If the number of primitives is
      below the maximum leaf size, it creates a leaf node. Otherwise, it
      computes a centroid bounding box of all primitives, selects the longest
      axis (i.e., the axis with the maximum extent), and then chooses the split
      point as the midpoint along that axis. <br />
      The midpoint heuristic aims to balance the tree by roughly dividing the
      primitives into two groups based on the position of their centroids. If
      the partitioning is degenerate (all primitives fall on one side), the
      algorithm defaults to splitting the set in half.

      <h3>
        Show images with normal shading for a few large¬†.dae¬†files that you can
        only render with BVH acceleration.
      </h3>

      <div style="display: flex; flex-direction: column; align-items: center">
        <table
          style="width: 80%; text-align: center; border-collapse: collapse"
        >
          <tr>
            <td style="text-align: center">
              <img src="Part2_beast.png" width="300px" alt="Beast" />
              <figcaption>Beast</figcaption>
            </td>
            <td style="text-align: center">
              <img src="Part2_blob.png" width="300px" alt="Blob" />
              <figcaption>Blob</figcaption>
            </td>
          </tr>
          <tr>
            <td style="text-align: center">
              <img src="Part2_CBlucy.png" width="300px" alt="CBlucy" />
              <figcaption>CBlucy</figcaption>
            </td>
            <td style="text-align: center" colspan="2">
              <img src="Part2_wall-e.png" width="300px" alt="Wall-e" />
              <figcaption>Wall-e</figcaption>
            </td>
          </tr>
        </table>
      </div>

      <h3>
        Compare rendering times on a few scenes with moderately complex
        geometries with and without BVH acceleration.
      </h3>

      For wall-e, with BVH, Building BVH from 240326 primitives takes 0.1627
      sec, and rendering takes 0.0678 sec. With the same processor but without
      BVH, rendering took 45 sec. All other renders above show a similar pattern
      that BVH significantly speed up rendering.

      <h2>Part 3: Direct Illumination</h2>
      Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod
      tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim
      veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea
      commodo consequat. Duis aute irure dolor in reprehenderit in voluptate
      velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat
      cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id
      est laborum.

      <h2>Part 4: Global Illumination</h2>
      Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod
      tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim
      veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea
      commodo consequat. Duis aute irure dolor in reprehenderit in voluptate
      velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat
      cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id
      est laborum.

      <h2>Part 5: Adaptive Sampling</h2>
      Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod
      tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim
      veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea
      commodo consequat. Duis aute irure dolor in reprehenderit in voluptate
      velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat
      cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id
      est laborum.

      <h2>(Optional) Part 6: Extra Credit Opportunities</h2>
      Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod
      tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim
      veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea
      commodo consequat. Duis aute irure dolor in reprehenderit in voluptate
      velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat
      cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id
      est laborum.

      <h2>Additional Notes (please remove)</h2>
      <ul>
        <li>
          You can also add code if you'd like as so: <code>code code code</code>
        </li>
        <li>
          If you'd like to add math equations,
          <ul>
            <li>
              You can write inline equations like so: \( a^2 + b^2 = c^2 \)
            </li>
            <li>
              You can write display equations like so: \[ a^2 + b^2 = c^2 \]
            </li>
          </ul>
        </li>
      </ul>
    </div>
  </body>
</html>
